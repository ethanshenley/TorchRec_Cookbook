{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import torch\n",
    "import torchrec\n",
    "import fbgemm_gpu\n",
    "from utils.environment import TorchRecEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker = TorchRecEnvironment()\n",
    "env_status = env_checker.check_environment()\n",
    "\n",
    "print(\"Environment Status:\")\n",
    "print(f\"CUDA Available: {env_status['cuda_available']}\")\n",
    "print(f\"GPU Count: {env_status['gpu_count']}\")\n",
    "print(f\"Distributed Available: {env_status['distributed_available']}\")\n",
    "print(f\"FBGEMM Available: {env_status['fbgemm_available']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic TorchRec Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrec import EmbeddingBagCollection\n",
    "from torchrec.modules.embedding_configs import EmbeddingBagConfig\n",
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "\n",
    "# Create a simple embedding bag configuration\n",
    "eb_configs = [\n",
    "    EmbeddingBagConfig(\n",
    "        name=\"simple_embedding\",\n",
    "        embedding_dim=16,\n",
    "        num_embeddings=100,\n",
    "        feature_names=[\"feature1\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize on CPU first\n",
    "ebc = EmbeddingBagCollection(\n",
    "    tables=eb_configs,\n",
    "    device=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test input\n",
    "values = torch.tensor([1, 2, 3, 4, 5])\n",
    "lengths = torch.tensor([2, 3])  # First sequence has 2 elements, second has 3\n",
    "\n",
    "# Create KeyedJaggedTensor\n",
    "kjt = KeyedJaggedTensor.from_lengths_sync(\n",
    "    keys=[\"feature1\"],\n",
    "    values=values,\n",
    "    lengths=lengths\n",
    ")\n",
    "\n",
    "# [MARKDOWN: Test Forward Pass]\n",
    "\n",
    "# Perform forward pass\n",
    "output = ebc(kjt)\n",
    "\n",
    "# Verify output\n",
    "print(\"\\nOutput Verification:\")\n",
    "print(f\"Output type: {type(output)}\")\n",
    "print(f\"Output keys: {output.keys()}\")\n",
    "print(f\"Output values shape: {output.values().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Test (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Move model to GPU\n",
    "    ebc_gpu = EmbeddingBagCollection(\n",
    "        tables=eb_configs,\n",
    "        device=torch.device(\"cuda\")\n",
    "    )\n",
    "    \n",
    "    # Move input to GPU\n",
    "    kjt_gpu = KeyedJaggedTensor.from_lengths_sync(\n",
    "        keys=[\"feature1\"],\n",
    "        values=values.cuda(),\n",
    "        lengths=lengths\n",
    "    )\n",
    "    \n",
    "    # Test forward pass on GPU\n",
    "    output_gpu = ebc_gpu(kjt_gpu)\n",
    "    \n",
    "    print(\"\\nGPU Output Verification:\")\n",
    "    print(f\"Output device: {output_gpu.values().device}\")\n",
    "    print(f\"Output shape: {output_gpu.values().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    from utils.debugging import TorchRecDebugger\n",
    "    \n",
    "    debugger = TorchRecDebugger()\n",
    "    \n",
    "    print(\"\\nMemory Status:\")\n",
    "    memory_stats = debugger.memory_status()\n",
    "    print(f\"Allocated: {memory_stats['allocated'] / 1e6:.2f} MB\")\n",
    "    print(f\"Reserved: {memory_stats['reserved'] / 1e6:.2f} MB\")\n",
    "    print(f\"Max Allocated: {memory_stats['max_allocated'] / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "if torch.cuda.is_available():\n",
    "    debugger.clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Installation Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = {\n",
    "    \"pytorch_installed\": True,\n",
    "    \"torchrec_installed\": True,\n",
    "    \"fbgemm_installed\": True,\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"can_create_ebc\": True,\n",
    "    \"can_forward_pass\": True,\n",
    "    \"gpu_working\": torch.cuda.is_available() and torch.cuda.device_count() > 0\n",
    "}\n",
    "\n",
    "print(\"\\nInstallation Checklist:\")\n",
    "for check, status in checklist.items():\n",
    "    print(f\"{check}: {'✅' if status else '❌'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
