{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchRec Embedding Tables Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchrec\n",
    "from torchrec import EmbeddingBagCollection\n",
    "from torchrec.modules.embedding_configs import EmbeddingBagConfig\n",
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "from utils.data_generators import TorchRecDataGenerator, DataConfig\n",
    "from utils.visualization import TorchRecVisualizer\n",
    "from utils.debugging import TorchRecDebugger\n",
    "from utils.benchmark import TorchRecBenchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Embedding Table Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic embedding table configuration\n",
    "basic_table = EmbeddingBagConfig(\n",
    "    name=\"basic_table\",\n",
    "    embedding_dim=16,\n",
    "    num_embeddings=1000,\n",
    "    feature_names=[\"feature1\"],\n",
    "    pooling=torchrec.PoolingType.SUM\n",
    ")\n",
    "\n",
    "# Initialize EmbeddingBagCollection\n",
    "basic_ebc = EmbeddingBagCollection(\n",
    "    tables=[basic_table],\n",
    "    device=torch.device(\"meta\")  # Start on meta device for memory efficiency\n",
    ")\n",
    "\n",
    "print(\"Basic Table Configuration:\")\n",
    "print(f\"Name: {basic_table.name}\")\n",
    "print(f\"Embedding Dimension: {basic_table.embedding_dim}\")\n",
    "print(f\"Number of Embeddings: {basic_table.num_embeddings}\")\n",
    "print(f\"Features: {basic_table.feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Table Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple tables with different configurations\n",
    "tables = [\n",
    "    EmbeddingBagConfig(\n",
    "        name=\"products\",\n",
    "        embedding_dim=64,\n",
    "        num_embeddings=100_000,\n",
    "        feature_names=[\"product_id\"],\n",
    "        pooling=torchrec.PoolingType.SUM\n",
    "    ),\n",
    "    EmbeddingBagConfig(\n",
    "        name=\"categories\",\n",
    "        embedding_dim=32,\n",
    "        num_embeddings=1_000,\n",
    "        feature_names=[\"category_id\"],\n",
    "        pooling=torchrec.PoolingType.MEAN\n",
    "    ),\n",
    "    EmbeddingBagConfig(\n",
    "        name=\"shared_features\",\n",
    "        embedding_dim=16,\n",
    "        num_embeddings=10_000,\n",
    "        feature_names=[\"search_term\", \"query_token\"],  # Shared embeddings\n",
    "        pooling=torchrec.PoolingType.SUM\n",
    "    )\n",
    "]\n",
    "\n",
    "multi_ebc = EmbeddingBagCollection(\n",
    "    tables=tables,\n",
    "    device=torch.device(\"meta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_memory_requirement(tables):\n",
    "    total_params = 0\n",
    "    memory_per_table = {}\n",
    "    \n",
    "    for table in tables:\n",
    "        params = table.num_embeddings * table.embedding_dim\n",
    "        memory_bytes = params * 4  # float32\n",
    "        total_params += params\n",
    "        memory_per_table[table.name] = {\n",
    "            \"parameters\": params,\n",
    "            \"memory_mb\": memory_bytes / (1024 * 1024)\n",
    "        }\n",
    "    \n",
    "    return memory_per_table, total_params\n",
    "\n",
    "memory_per_table, total_params = calculate_memory_requirement(tables)\n",
    "\n",
    "print(\"\\nMemory Requirements:\")\n",
    "for table_name, info in memory_per_table.items():\n",
    "    print(f\"{table_name}:\")\n",
    "    print(f\"  Parameters: {info['parameters']:,}\")\n",
    "    print(f\"  Memory: {info['memory_mb']:.2f} MB\")\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ebc = EmbeddingBagCollection(tables=tables, device=device)\n",
    "\n",
    "# Generate sample input data\n",
    "data_gen = TorchRecDataGenerator(DataConfig(\n",
    "    num_users=100,\n",
    "    num_products=100_000,\n",
    "    max_sequence_length=10,\n",
    "    batch_size=32\n",
    "))\n",
    "\n",
    "# Create input features\n",
    "kjt_inputs = data_gen.generate_kjt_inputs([\n",
    "    \"product_id\",\n",
    "    \"category_id\",\n",
    "    \"search_term\",\n",
    "    \"query_token\"\n",
    "])\n",
    "\n",
    "kjt = KeyedJaggedTensor.from_lengths_sync(\n",
    "    keys=kjt_inputs[\"keys\"],\n",
    "    values=kjt_inputs[\"values\"].to(device),\n",
    "    lengths=kjt_inputs[\"lengths\"]\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "embeddings = ebc(kjt)\n",
    "\n",
    "print(\"\\nEmbedding Output Structure:\")\n",
    "print(f\"Keys: {embeddings.keys()}\")\n",
    "print(f\"Values shape: {embeddings.values().shape}\")\n",
    "print(f\"Length per key: {embeddings.length_per_key()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = TorchRecVisualizer()\n",
    "\n",
    "# Analyze embedding distributions\n",
    "for key in embeddings.keys():\n",
    "    emb_dict = embeddings.to_dict()\n",
    "    print(f\"\\nAnalyzing {key} embeddings:\")\n",
    "    print(f\"Mean: {emb_dict[key].mean().item():.4f}\")\n",
    "    print(f\"Std: {emb_dict[key].std().item():.4f}\")\n",
    "    visualizer.plot_embedding_distribution(emb_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = TorchRecBenchmark(\n",
    "    warmup_steps=3,\n",
    "    measure_steps=10\n",
    ")\n",
    "\n",
    "# Benchmark forward pass\n",
    "result = benchmark.benchmark_forward(\n",
    "    model=ebc,\n",
    "    sample_input=kjt,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Average batch time: {result.batch_time_ms:.2f}ms\")\n",
    "print(f\"Memory used: {result.memory_used_gb:.2f}GB\")\n",
    "print(f\"Throughput: {result.throughput:.2f} examples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with custom initialization\n",
    "custom_init_table = EmbeddingBagConfig(\n",
    "    name=\"custom_init\",\n",
    "    embedding_dim=32,\n",
    "    num_embeddings=1000,\n",
    "    feature_names=[\"custom_feature\"],\n",
    "    pooling=torchrec.PoolingType.SUM,\n",
    "    weight_init_max=0.1,\n",
    "    weight_init_min=-0.1\n",
    ")\n",
    "\n",
    "# Example with different pooling types\n",
    "pooling_examples = {\n",
    "    \"sum\": torchrec.PoolingType.SUM,\n",
    "    \"mean\": torchrec.PoolingType.MEAN\n",
    "}\n",
    "\n",
    "for name, pooling_type in pooling_examples.items():\n",
    "    table = EmbeddingBagConfig(\n",
    "        name=f\"pooling_{name}\",\n",
    "        embedding_dim=16,\n",
    "        num_embeddings=100,\n",
    "        feature_names=[f\"feature_{name}\"],\n",
    "        pooling=pooling_type\n",
    "    )\n",
    "    \n",
    "    ebc_pool = EmbeddingBagCollection(\n",
    "        tables=[table],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Create sample input\n",
    "    sample_kjt = KeyedJaggedTensor.from_lengths_sync(\n",
    "        keys=[f\"feature_{name}\"],\n",
    "        values=torch.tensor([1, 2, 3, 4, 5]).to(device),\n",
    "        lengths=torch.tensor([2, 3])\n",
    "    )\n",
    "    \n",
    "    output = ebc_pool(sample_kjt)\n",
    "    print(f\"\\n{name.upper()} Pooling Output:\")\n",
    "    print(output.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_practices = {\n",
    "    \"Memory Management\": [\n",
    "        \"Use meta device for initialization\",\n",
    "        \"Calculate memory requirements beforehand\",\n",
    "        \"Consider sharing embeddings for related features\"\n",
    "    ],\n",
    "    \"Performance\": [\n",
    "        \"Choose appropriate embedding dimensions\",\n",
    "        \"Use efficient pooling types\",\n",
    "        \"Batch similar operations\"\n",
    "    ],\n",
    "    \"Architecture\": [\n",
    "        \"Group related features\",\n",
    "        \"Plan for vocabulary size growth\",\n",
    "        \"Consider embedding dimension carefully\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\nBest Practices:\")\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"- {practice}\")\n",
    "\n",
    "# Cleanup\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
