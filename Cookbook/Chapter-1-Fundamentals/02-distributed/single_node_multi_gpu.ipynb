{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Node Multi-GPU Training with TorchRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchrec\n",
    "import torch.distributed as dist\n",
    "from torchrec.distributed.model_parallel import DistributedModelParallel\n",
    "from torchrec.distributed.planner import EmbeddingShardingPlanner, Topology\n",
    "from torchrec.distributed.types import ShardingType, ShardingEnv\n",
    "from utils.debugging import TorchRecDebugger\n",
    "from utils.benchmark import TorchRecBenchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_distributed(rank: int, world_size: int):\n",
    "    \"\"\"Initialize distributed environment\"\"\"\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "    os.environ[\"WORLD_SIZE\"] = str(world_size)\n",
    "    os.environ[\"RANK\"] = str(rank)\n",
    "    \n",
    "    # Initialize process group\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "# Check available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding tables\n",
    "tables = [\n",
    "    torchrec.EmbeddingBagConfig(\n",
    "        name=\"large_table\",\n",
    "        embedding_dim=128,\n",
    "        num_embeddings=1_000_000,\n",
    "        feature_names=[\"large_features\"],\n",
    "        pooling=torchrec.PoolingType.SUM,\n",
    "    ),\n",
    "    torchrec.EmbeddingBagConfig(\n",
    "        name=\"medium_table\",\n",
    "        embedding_dim=64,\n",
    "        num_embeddings=100_000,\n",
    "        feature_names=[\"medium_features\"],\n",
    "        pooling=torchrec.PoolingType.SUM,\n",
    "    ),\n",
    "    torchrec.EmbeddingBagConfig(\n",
    "        name=\"small_table\",\n",
    "        embedding_dim=32,\n",
    "        num_embeddings=10_000,\n",
    "        feature_names=[\"small_features\"],\n",
    "        pooling=torchrec.PoolingType.SUM,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create base model\n",
    "model = torchrec.EmbeddingBagCollection(\n",
    "    tables=tables,\n",
    "    device=torch.device(\"meta\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharding Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sharding constraints\n",
    "constraints = {\n",
    "    \"large_table\": torchrec.distributed.types.ParameterConstraints(\n",
    "        sharding_types=[ShardingType.ROW_WISE.value]\n",
    "    ),\n",
    "    \"medium_table\": torchrec.distributed.types.ParameterConstraints(\n",
    "        sharding_types=[ShardingType.TABLE_WISE.value]\n",
    "    ),\n",
    "    \"small_table\": torchrec.distributed.types.ParameterConstraints(\n",
    "        sharding_types=[ShardingType.TABLE_WISE.value]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Distributed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distributed_model(model, rank, world_size):\n",
    "    \"\"\"Create distributed model with sharding plan\"\"\"\n",
    "    # Initialize distributed environment\n",
    "    setup_distributed(rank, world_size)\n",
    "    \n",
    "    # Define topology\n",
    "    topology = Topology(\n",
    "        world_size=world_size,\n",
    "        compute_device=\"cuda\"\n",
    "    )\n",
    "    \n",
    "    # Create planner\n",
    "    planner = EmbeddingShardingPlanner(\n",
    "        topology=topology,\n",
    "        constraints=constraints\n",
    "    )\n",
    "    \n",
    "    # Generate plan\n",
    "    plan = planner.collective_plan(\n",
    "        model, \n",
    "        [torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder()]\n",
    "    )\n",
    "    \n",
    "    # Create distributed model\n",
    "    distributed_model = DistributedModelParallel(\n",
    "        module=model,\n",
    "        device=torch.device(f\"cuda:{rank}\"),\n",
    "        plan=plan\n",
    "    )\n",
    "    \n",
    "    return distributed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size: int, num_gpus: int):\n",
    "    \"\"\"Generate sample batch data\"\"\"\n",
    "    values = []\n",
    "    lengths = []\n",
    "    \n",
    "    for feature in [\"large_features\", \"medium_features\", \"small_features\"]:\n",
    "        # Generate values and lengths for each feature\n",
    "        feature_values = torch.randint(0, 1000, (batch_size * 10,))\n",
    "        feature_lengths = torch.ones(batch_size) * 10\n",
    "        \n",
    "        values.append(feature_values)\n",
    "        lengths.append(feature_lengths)\n",
    "    \n",
    "    # Create KJT\n",
    "    kjt = torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_lengths_sync(\n",
    "        keys=[\"large_features\", \"medium_features\", \"small_features\"],\n",
    "        values=torch.cat(values),\n",
    "        lengths=torch.cat(lengths)\n",
    "    )\n",
    "    \n",
    "    return kjt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer):\n",
    "    \"\"\"Single training step\"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass (returns LazyAwaitable)\n",
    "    output = model(batch)\n",
    "    \n",
    "    # Wait for embeddings and compute loss\n",
    "    embeddings = output.wait()\n",
    "    loss = torch.mean(embeddings.values())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(rank, world_size, num_iterations=10):\n",
    "    \"\"\"Run complete training loop\"\"\"\n",
    "    # Create distributed model\n",
    "    dist_model = create_distributed_model(model, rank, world_size)\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.Adam(dist_model.parameters())\n",
    "    \n",
    "    # Training loop\n",
    "    for iteration in range(num_iterations):\n",
    "        # Generate batch\n",
    "        batch = generate_batch(batch_size=32, num_gpus=world_size)\n",
    "        \n",
    "        # Move batch to correct device\n",
    "        batch = batch.to(torch.device(f\"cuda:{rank}\"))\n",
    "        \n",
    "        # Training step\n",
    "        loss = train_step(dist_model, batch, optimizer)\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\"Iteration {iteration}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_performance(rank, model, batch):\n",
    "    \"\"\"Monitor distributed training performance\"\"\"\n",
    "    debugger = TorchRecDebugger()\n",
    "    benchmark = TorchRecBenchmark()\n",
    "    \n",
    "    # Memory status\n",
    "    memory_stats = debugger.memory_status()\n",
    "    print(f\"\\nRank {rank} Memory Usage:\")\n",
    "    print(f\"Allocated: {memory_stats['allocated'] / 1e9:.2f} GB\")\n",
    "    print(f\"Reserved: {memory_stats['reserved'] / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Performance benchmark\n",
    "    results = benchmark.benchmark_forward(model, batch, batch_size=32)\n",
    "    print(f\"\\nRank {rank} Performance:\")\n",
    "    print(f\"Batch Time: {results.batch_time_ms:.2f} ms\")\n",
    "    print(f\"Throughput: {results.throughput:.2f} examples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    if world_size > 1:\n",
    "        mp.spawn(\n",
    "            run_training,\n",
    "            args=(world_size,),\n",
    "            nprocs=world_size,\n",
    "            join=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"Multiple GPUs required for this example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_tips = {\n",
    "    \"Initialization\": [\n",
    "        \"Always use meta device initially\",\n",
    "        \"Set appropriate sharding constraints\",\n",
    "        \"Verify process group initialization\"\n",
    "    ],\n",
    "    \"Performance\": [\n",
    "        \"Monitor per-GPU memory usage\",\n",
    "        \"Use appropriate batch sizes\",\n",
    "        \"Consider communication overhead\"\n",
    "    ],\n",
    "    \"Debug\": [\n",
    "        \"Start with small tables\",\n",
    "        \"Monitor memory usage\",\n",
    "        \"Check device placement\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\nDistributed Training Tips:\")\n",
    "for category, tips in distributed_tips.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for tip in tips:\n",
    "        print(f\"- {tip}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
