{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Basic Product Recommender with TorchRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchrec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "from utils.data_generators import TorchRecDataGenerator\n",
    "from utils.debugging import TorchRecDebugger\n",
    "from utils.benchmark import TorchRecBenchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductRecommender(torch.nn.Module):\n",
    "    \"\"\"Two-tower model for product recommendations\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_products: int,\n",
    "        num_categories: int,\n",
    "        embedding_dim: int = 64,\n",
    "        hidden_dim: int = 128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define embedding tables\n",
    "        self.embedding_tables = torchrec.EmbeddingBagCollection(\n",
    "            tables=[\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"product_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_products,\n",
    "                    feature_names=[\"product_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"category_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_categories,\n",
    "                    feature_names=[\"category_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"product_history\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_products,\n",
    "                    feature_names=[\"history\"],\n",
    "                ),\n",
    "            ],\n",
    "            device=torch.device(\"meta\"),  # Start on meta device\n",
    "        )\n",
    "        \n",
    "        # User tower (processes user history)\n",
    "        self.user_tower = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim * 2, hidden_dim),  # Combine history + category\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "        # Item tower (processes candidate items)\n",
    "        self.item_tower = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim * 2, hidden_dim),  # Combine product + category\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        user_features: KeyedJaggedTensor,\n",
    "        item_features: KeyedJaggedTensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # Get embeddings\n",
    "        user_embeddings = self.embedding_tables(user_features)\n",
    "        item_embeddings = self.embedding_tables(item_features)\n",
    "        \n",
    "        # Process user features\n",
    "        user_history = user_embeddings.to_dict()[\"history\"]\n",
    "        user_categories = user_embeddings.to_dict()[\"category_id\"]\n",
    "        user_combined = torch.cat([user_history, user_categories], dim=1)\n",
    "        user_vector = self.user_tower(user_combined)\n",
    "        \n",
    "        # Process item features\n",
    "        item_product = item_embeddings.to_dict()[\"product_id\"]\n",
    "        item_category = item_embeddings.to_dict()[\"category_id\"]\n",
    "        item_combined = torch.cat([item_product, item_category], dim=1)\n",
    "        item_vector = self.item_tower(item_combined)\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        return torch.matmul(user_vector, item_vector.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderDataGenerator:\n",
    "    \"\"\"Generate synthetic data for recommendation system\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_products: int,\n",
    "        num_categories: int,\n",
    "        max_history_length: int = 10,\n",
    "    ):\n",
    "        self.num_users = num_users\n",
    "        self.num_products = num_products\n",
    "        self.num_categories = num_categories\n",
    "        self.max_history_length = max_history_length\n",
    "        \n",
    "        # Generate product categories\n",
    "        self.product_categories = torch.randint(\n",
    "            0, num_categories, (num_products,)\n",
    "        )\n",
    "    \n",
    "    def generate_user_features(self, batch_size: int) -> KeyedJaggedTensor:\n",
    "        \"\"\"Generate user features including history\"\"\"\n",
    "        # Generate random history lengths\n",
    "        history_lengths = torch.randint(\n",
    "            1, self.max_history_length + 1, (batch_size,)\n",
    "        )\n",
    "        \n",
    "        # Generate product history\n",
    "        history_values = torch.randint(\n",
    "            0, self.num_products, (history_lengths.sum(),)\n",
    "        )\n",
    "        \n",
    "        # Get categories for history items\n",
    "        category_values = self.product_categories[history_values]\n",
    "        \n",
    "        return KeyedJaggedTensor.from_lengths_sync(\n",
    "            keys=[\"history\", \"category_id\"],\n",
    "            values=torch.cat([history_values, category_values]),\n",
    "            lengths=torch.cat([history_lengths, history_lengths])\n",
    "        )\n",
    "    \n",
    "    def generate_item_features(self, batch_size: int) -> KeyedJaggedTensor:\n",
    "        \"\"\"Generate candidate item features\"\"\"\n",
    "        # Sample random products\n",
    "        products = torch.randint(0, self.num_products, (batch_size,))\n",
    "        \n",
    "        # Get their categories\n",
    "        categories = self.product_categories[products]\n",
    "        \n",
    "        return KeyedJaggedTensor.from_lengths_sync(\n",
    "            keys=[\"product_id\", \"category_id\"],\n",
    "            values=torch.cat([products, categories]),\n",
    "            lengths=torch.ones(2 * batch_size)  # One value per feature\n",
    "        )\n",
    "    \n",
    "    def generate_batch(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        num_negatives: int = 4,\n",
    "    ) -> Tuple[KeyedJaggedTensor, KeyedJaggedTensor, torch.Tensor]:\n",
    "        \"\"\"Generate complete training batch with negatives\"\"\"\n",
    "        # Generate user features\n",
    "        user_features = self.generate_user_features(batch_size)\n",
    "        \n",
    "        # Generate positive items\n",
    "        pos_items = self.generate_item_features(batch_size)\n",
    "        \n",
    "        # Generate negative items\n",
    "        neg_items = self.generate_item_features(batch_size * num_negatives)\n",
    "        \n",
    "        # Create labels (1 for positive, 0 for negative)\n",
    "        labels = torch.cat([\n",
    "            torch.ones(batch_size),\n",
    "            torch.zeros(batch_size * num_negatives)\n",
    "        ])\n",
    "        \n",
    "        return user_features, pos_items, neg_items, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderTrainer:\n",
    "    \"\"\"Trainer for product recommender\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: ProductRecommender,\n",
    "        learning_rate: float = 0.001,\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.device = device\n",
    "        self.debugger = TorchRecDebugger()\n",
    "        \n",
    "    def train_step(\n",
    "        self,\n",
    "        user_features: KeyedJaggedTensor,\n",
    "        pos_items: KeyedJaggedTensor,\n",
    "        neg_items: KeyedJaggedTensor,\n",
    "        labels: torch.Tensor,\n",
    "    ) -> float:\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Move inputs to device\n",
    "        user_features = user_features.to(self.device)\n",
    "        pos_items = pos_items.to(self.device)\n",
    "        neg_items = neg_items.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        \n",
    "        # Combine positive and negative items\n",
    "        all_items = KeyedJaggedTensor.concat([pos_items, neg_items])\n",
    "        \n",
    "        # Forward pass\n",
    "        scores = self.model(user_features, all_items)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            scores.view(-1), labels.float()\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def train_epoch(\n",
    "        self,\n",
    "        data_generator: RecommenderDataGenerator,\n",
    "        batch_size: int,\n",
    "        num_batches: int,\n",
    "    ) -> List[float]:\n",
    "        losses = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # Generate batch\n",
    "            user_features, pos_items, neg_items, labels = \\\n",
    "                data_generator.generate_batch(batch_size)\n",
    "            \n",
    "            # Train step\n",
    "            loss = self.train_step(user_features, pos_items, neg_items, labels)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"Batch {i}, Loss: {loss:.4f}\")\n",
    "                \n",
    "                # Monitor memory\n",
    "                memory_stats = self.debugger.memory_status()\n",
    "                print(f\"Memory used: {memory_stats['allocated'] / 1e9:.2f}GB\")\n",
    "        \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderEvaluator:\n",
    "    \"\"\"Evaluate recommender model\"\"\"\n",
    "    def __init__(self, model: ProductRecommender, device: str = \"cuda\"):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate_batch(\n",
    "        self,\n",
    "        user_features: KeyedJaggedTensor,\n",
    "        item_features: KeyedJaggedTensor,\n",
    "        labels: torch.Tensor,\n",
    "    ) -> Dict[str, float]:\n",
    "        # Move to device\n",
    "        user_features = user_features.to(self.device)\n",
    "        item_features = item_features.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        \n",
    "        # Get predictions\n",
    "        scores = self.model(user_features, item_features)\n",
    "        predictions = torch.sigmoid(scores)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        auc = self.compute_auc(predictions.view(-1), labels)\n",
    "        precision = self.compute_precision_at_k(predictions.view(-1), labels, k=10)\n",
    "        \n",
    "        return {\n",
    "            \"auc\": auc,\n",
    "            \"precision@10\": precision,\n",
    "        }\n",
    "    \n",
    "    def compute_auc(\n",
    "        self,\n",
    "        predictions: torch.Tensor,\n",
    "        labels: torch.Tensor,\n",
    "    ) -> float:\n",
    "        # Sort predictions and corresponding labels\n",
    "        sorted_pred, indices = torch.sort(predictions, descending=True)\n",
    "        sorted_labels = labels[indices]\n",
    "        \n",
    "        # Compute AUC\n",
    "        pos = sorted_labels.sum()\n",
    "        neg = len(sorted_labels) - pos\n",
    "        if pos == 0 or neg == 0:\n",
    "            return 0.5\n",
    "        \n",
    "        pos_ranks = torch.where(sorted_labels == 1)[0]\n",
    "        auc = (pos_ranks.float().sum() / pos - (pos + 1) / 2) / neg\n",
    "        return auc.item()\n",
    "    \n",
    "    def compute_precision_at_k(\n",
    "        self,\n",
    "        predictions: torch.Tensor,\n",
    "        labels: torch.Tensor,\n",
    "        k: int,\n",
    "    ) -> float:\n",
    "        # Get top k predictions\n",
    "        _, top_k = torch.topk(predictions, k)\n",
    "        \n",
    "        # Calculate precision\n",
    "        return labels[top_k].float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_recommender(\n",
    "    num_users: int = 10000,\n",
    "    num_products: int = 1000,\n",
    "    num_categories: int = 100,\n",
    "    batch_size: int = 64,\n",
    "    num_epochs: int = 5,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    # Create data generator\n",
    "    data_gen = RecommenderDataGenerator(\n",
    "        num_users=num_users,\n",
    "        num_products=num_products,\n",
    "        num_categories=num_categories,\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = ProductRecommender(\n",
    "        num_products=num_products,\n",
    "        num_categories=num_categories,\n",
    "    )\n",
    "    \n",
    "    # Create trainer and evaluator\n",
    "    trainer = RecommenderTrainer(model, device=device)\n",
    "    evaluator = RecommenderEvaluator(model, device=device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        \n",
    "        # Train\n",
    "        losses = trainer.train_epoch(\n",
    "            data_generator=data_gen,\n",
    "            batch_size=batch_size,\n",
    "            num_batches=100,\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        user_features, pos_items, neg_items, labels = \\\n",
    "            data_gen.generate_batch(batch_size=1000)\n",
    "        \n",
    "        metrics = evaluator.evaluate_batch(\n",
    "            user_features,\n",
    "            KeyedJaggedTensor.concat([pos_items, neg_items]),\n",
    "            labels,\n",
    "        )\n",
    "        \n",
    "        print(f\"Average Loss: {sum(losses) / len(losses):.4f}\")\n",
    "        print(f\"AUC: {metrics['auc']:.4f}\")\n",
    "        print(f\"Precision@10: {metrics['precision@10']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelAnalyzer:\n",
    "    \"\"\"Analyze trained recommender model\"\"\"\n",
    "    def __init__(self, model: ProductRecommender):\n",
    "        self.model = model\n",
    "    \n",
    "    def analyze_embeddings(self):\n",
    "        \"\"\"Analyze embedding distributions\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'embedding' in name:\n",
    "                stats[name] = {\n",
    "                    'mean': param.mean().item(),\n",
    "                    'std': param.std().item(),\n",
    "                    'norm': param.norm().item(),\n",
    "                }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def get_similar_products(\n",
    "        self,\n",
    "        product_id: int,\n",
    "        top_k: int = 5,\n",
    "        data_gen: RecommenderDataGenerator = None,\n",
    "    ) -> List[Tuple[int, float]]:\n",
    "        \"\"\"Find similar products based on embeddings\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Get product embedding\n",
    "            product_feature = KeyedJaggedTensor.from_lengths_sync(\n",
    "                keys=[\"product_id\"],\n",
    "                values=torch.tensor([product_id]),\n",
    "                lengths=torch.ones(1),\n",
    "            )\n",
    "            \n",
    "            # Get category\n",
    "            category = data_gen.product_categories[product_id].item()\n",
    "            category_feature = KeyedJaggedTensor.from_lengths_sync(\n",
    "                keys=[\"category_id\"],\n",
    "                values=torch.tensor([category]),\n",
    "                lengths=torch.ones(1),\n",
    "            )\n",
    "            \n",
    "            # Get combined features\n",
    "            features = KeyedJaggedTensor.concat([product_feature, category_feature])\n",
    "            \n",
    "            # Get embedding\n",
    "            embeddings = self.model.item_tower(\n",
    "                torch.cat([\n",
    "                    self.model.embedding_tables(features).to_dict()['product_id'],\n",
    "                    self.model.embedding_tables(features).to_dict()['category_id'],\n",
    "                ], dim=1)\n",
    "            )\n",
    "            \n",
    "            # Compute similarities\n",
    "            all_embeddings = []\n",
    "            for pid in range(data_gen.num_products):\n",
    "                pf = KeyedJaggedTensor.from_lengths_sync(\n",
    "                    keys=[\"product_id\"],\n",
    "                    values=torch.tensor([pid]),\n",
    "                    lengths=torch.ones(1),\n",
    "                )\n",
    "                cat = data_gen.product_categories[pid].item()\n",
    "                cf = KeyedJaggedTensor.from_lengths_sync(\n",
    "                    keys=[\"category_id\"],\n",
    "                    values=torch.tensor([cat]),\n",
    "                    lengths=torch.ones(1),\n",
    "                )\n",
    "                f = KeyedJaggedTensor.concat([pf, cf])\n",
    "                emb = self.model.item_tower(\n",
    "                    torch.cat([\n",
    "                        self.model.embedding_tables(f).to_dict()['product_id'],\n",
    "                        self.model.embedding_tables(f).to_dict()['category_id'],\n",
    "                    ], dim=1)\n",
    "                )\n",
    "                all_embeddings.append(emb)\n",
    "            \n",
    "            all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "            similarities = torch.matmul(embeddings, all_embeddings.t())\n",
    "            \n",
    "            # Get top-k similar products\n",
    "            top_values, top_indices = similarities[0].topk(top_k + 1)\n",
    "            \n",
    "            # Remove the query product itself\n",
    "            mask = top_indices != product_id\n",
    "            top_values = top_values[mask][:top_k]\n",
    "            top_indices = top_indices[mask][:top_k]\n",
    "            \n",
    "            return list(zip(top_indices.tolist(), top_values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize components\n",
    "    print(\"Initializing recommender system...\")\n",
    "    \n",
    "    num_products = 1000\n",
    "    num_categories = 50\n",
    "    batch_size = 64\n",
    "    embedding_dim = 64\n",
    "    \n",
    "    # Create model and move to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ProductRecommender(\n",
    "        num_products=num_products,\n",
    "        num_categories=num_categories,\n",
    "        embedding_dim=embedding_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create data generator\n",
    "    data_gen = RecommenderDataGenerator(\n",
    "        num_users=10000,\n",
    "        num_products=num_products,\n",
    "        num_categories=num_categories\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining model...\")\n",
    "    trainer = RecommenderTrainer(model, device=device)\n",
    "    evaluator = RecommenderEvaluator(model, device=device)\n",
    "    \n",
    "    for epoch in range(3):  # 3 epochs for demonstration\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        losses = trainer.train_epoch(data_gen, batch_size, num_batches=50)\n",
    "        \n",
    "        # Evaluation\n",
    "        user_features, pos_items, neg_items, labels = data_gen.generate_batch(1000)\n",
    "        metrics = evaluator.evaluate_batch(\n",
    "            user_features,\n",
    "            KeyedJaggedTensor.concat([pos_items, neg_items]),\n",
    "            labels\n",
    "        )\n",
    "        \n",
    "        print(f\"Average Loss: {sum(losses) / len(losses):.4f}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "    \n",
    "    # Analyze model\n",
    "    print(\"\\nAnalyzing model...\")\n",
    "    analyzer = ModelAnalyzer(model)\n",
    "    embedding_stats = analyzer.analyze_embeddings()\n",
    "    print(\"\\nEmbedding Statistics:\")\n",
    "    for name, stats in embedding_stats.items():\n",
    "        print(f\"{name}:\")\n",
    "        for stat_name, value in stats.items():\n",
    "            print(f\"  {stat_name}: {value:.4f}\")\n",
    "    \n",
    "    # Generate recommendations\n",
    "    print(\"\\nGenerating sample recommendations...\")\n",
    "    sample_product_id = 42\n",
    "    similar_products = analyzer.get_similar_products(\n",
    "        sample_product_id,\n",
    "        top_k=5,\n",
    "        data_gen=data_gen\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nProducts similar to product {sample_product_id}:\")\n",
    "    for product_id, similarity in similar_products:\n",
    "        category = data_gen.product_categories[product_id].item()\n",
    "        print(f\"Product {product_id} (Category {category}): {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_performance():\n",
    "    \"\"\"Demonstrate performance optimization techniques\"\"\"\n",
    "    debugger = TorchRecDebugger()\n",
    "    benchmark = TorchRecBenchmark()\n",
    "    \n",
    "    print(\"\\nPerformance optimization tips:\")\n",
    "    \n",
    "    # 1. Memory optimization\n",
    "    print(\"\\n1. Memory Management:\")\n",
    "    memory_tips = {\n",
    "        \"Use meta device\": \"Initialize model on meta device first\",\n",
    "        \"Batch size tuning\": \"Adjust batch size based on available memory\",\n",
    "        \"Gradient checkpointing\": \"Use if memory is constrained\",\n",
    "        \"Clear cache\": \"Regularly clear unused memory\"\n",
    "    }\n",
    "    for tip, description in memory_tips.items():\n",
    "        print(f\"- {tip}: {description}\")\n",
    "    \n",
    "    # 2. Computation optimization\n",
    "    print(\"\\n2. Computation Optimization:\")\n",
    "    compute_tips = {\n",
    "        \"Mixed precision\": \"Use torch.cuda.amp for faster training\",\n",
    "        \"Parallel data loading\": \"Use multiple workers for data loading\",\n",
    "        \"Embedding sharing\": \"Share embeddings when appropriate\",\n",
    "        \"Batch compilation\": \"Use torch.compile for faster execution\"\n",
    "    }\n",
    "    for tip, description in compute_tips.items():\n",
    "        print(f\"- {tip}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production_checklist():\n",
    "    \"\"\"Checklist for production deployment\"\"\"\n",
    "    checklist = {\n",
    "        \"Model Preparation\": [\n",
    "            \"Quantize embeddings for inference\",\n",
    "            \"Export model to TorchScript\",\n",
    "            \"Implement model versioning\",\n",
    "            \"Set up monitoring\"\n",
    "        ],\n",
    "        \"Data Pipeline\": [\n",
    "            \"Implement efficient data loading\",\n",
    "            \"Set up feature preprocessing\",\n",
    "            \"Handle missing values\",\n",
    "            \"Implement data validation\"\n",
    "        ],\n",
    "        \"Performance\": [\n",
    "            \"Optimize batch size\",\n",
    "            \"Implement caching\",\n",
    "            \"Monitor memory usage\",\n",
    "            \"Set up performance logging\"\n",
    "        ],\n",
    "        \"Monitoring\": [\n",
    "            \"Track recommendation quality\",\n",
    "            \"Monitor resource usage\",\n",
    "            \"Set up alerting\",\n",
    "            \"Implement A/B testing\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nProduction Deployment Checklist:\")\n",
    "    for category, items in checklist.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"- {item}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    optimize_performance()\n",
    "    production_checklist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
