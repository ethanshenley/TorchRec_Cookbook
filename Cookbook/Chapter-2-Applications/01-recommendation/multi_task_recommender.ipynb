{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Task Recommendation System with TorchRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchrec\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, NamedTuple\n",
    "from dataclasses import dataclass\n",
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "from utils.data_generators import TorchRecDataGenerator\n",
    "from utils.debugging import TorchRecDebugger\n",
    "from utils.benchmark import TorchRecBenchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TaskConfig:\n",
    "    \"\"\"Configuration for each prediction task\"\"\"\n",
    "    name: str\n",
    "    weight: float\n",
    "    metric_type: str  # 'binary', 'regression', 'ranking'\n",
    "    loss_type: str    # 'bce', 'mse', 'hinge'\n",
    "\n",
    "class MultiTaskTargets(NamedTuple):\n",
    "    \"\"\"Container for multiple task targets\"\"\"\n",
    "    click: torch.Tensor\n",
    "    purchase: torch.Tensor\n",
    "    watch_time: torch.Tensor\n",
    "    rating: torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTower(torch.nn.Module):\n",
    "    \"\"\"Task-specific tower network\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dims: List[int],\n",
    "        output_dim: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                torch.nn.Linear(prev_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.BatchNorm1d(hidden_dim),\n",
    "                torch.nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(torch.nn.Linear(prev_dim, output_dim))\n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x)\n",
    "\n",
    "class MultiTaskRecommender(torch.nn.Module):\n",
    "    \"\"\"Multi-task recommendation model\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "        embedding_dim: int = 64,\n",
    "        hidden_dim: int = 128,\n",
    "        tower_hidden_dims: List[int] = [256, 128],\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared embedding layer\n",
    "        self.embedding_tables = torchrec.EmbeddingBagCollection(\n",
    "            tables=[\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"item_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_items,\n",
    "                    feature_names=[\"item_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"category_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_categories,\n",
    "                    feature_names=[\"category_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"user_history\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_items,\n",
    "                    feature_names=[\"history\"],\n",
    "                ),\n",
    "            ],\n",
    "            device=torch.device(\"meta\")\n",
    "        )\n",
    "        \n",
    "        # Shared bottom network\n",
    "        self.shared_network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim * 3, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Task-specific towers\n",
    "        self.click_tower = MultiTaskTower(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dims=tower_hidden_dims,\n",
    "            output_dim=1\n",
    "        )\n",
    "        \n",
    "        self.purchase_tower = MultiTaskTower(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dims=tower_hidden_dims,\n",
    "            output_dim=1\n",
    "        )\n",
    "        \n",
    "        self.watch_time_tower = MultiTaskTower(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dims=tower_hidden_dims,\n",
    "            output_dim=1\n",
    "        )\n",
    "        \n",
    "        self.rating_tower = MultiTaskTower(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dims=tower_hidden_dims,\n",
    "            output_dim=1\n",
    "        )\n",
    "        \n",
    "        # Task configurations\n",
    "        self.task_configs = {\n",
    "            \"click\": TaskConfig(\"click\", 1.0, \"binary\", \"bce\"),\n",
    "            \"purchase\": TaskConfig(\"purchase\", 2.0, \"binary\", \"bce\"),\n",
    "            \"watch_time\": TaskConfig(\"watch_time\", 0.5, \"regression\", \"mse\"),\n",
    "            \"rating\": TaskConfig(\"rating\", 1.0, \"regression\", \"mse\")\n",
    "        }\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        user_features: KeyedJaggedTensor,\n",
    "        item_features: KeyedJaggedTensor\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # Get embeddings\n",
    "        user_embeddings = self.embedding_tables(user_features)\n",
    "        item_embeddings = self.embedding_tables(item_features)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        combined_embeddings = torch.cat([\n",
    "            user_embeddings.to_dict()[\"user_history\"],\n",
    "            item_embeddings.to_dict()[\"item_embeddings\"],\n",
    "            item_embeddings.to_dict()[\"category_embeddings\"]\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Shared representation\n",
    "        shared_repr = self.shared_network(combined_embeddings)\n",
    "        \n",
    "        # Task-specific predictions\n",
    "        return {\n",
    "            \"click\": self.click_tower(shared_repr),\n",
    "            \"purchase\": self.purchase_tower(shared_repr),\n",
    "            \"watch_time\": self.watch_time_tower(shared_repr),\n",
    "            \"rating\": self.rating_tower(shared_repr)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskLoss:\n",
    "    \"\"\"Handle multiple loss functions with weighting\"\"\"\n",
    "    def __init__(self, task_configs: Dict[str, TaskConfig]):\n",
    "        self.task_configs = task_configs\n",
    "        \n",
    "        self.loss_fns = {\n",
    "            \"bce\": torch.nn.BCEWithLogitsLoss(reduction='none'),\n",
    "            \"mse\": torch.nn.MSELoss(reduction='none'),\n",
    "            \"hinge\": torch.nn.HingeEmbeddingLoss(reduction='none')\n",
    "        }\n",
    "    \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        predictions: Dict[str, torch.Tensor],\n",
    "        targets: MultiTaskTargets,\n",
    "        mask: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        task_losses = {}\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for task_name, pred in predictions.items():\n",
    "            config = self.task_configs[task_name]\n",
    "            target = getattr(targets, task_name)\n",
    "            \n",
    "            # Compute task-specific loss\n",
    "            loss = self.loss_fns[config.loss_type](\n",
    "                pred.squeeze(),\n",
    "                target.float()\n",
    "            )\n",
    "            \n",
    "            # Apply mask if provided\n",
    "            if mask is not None:\n",
    "                loss = loss * mask\n",
    "            \n",
    "            # Average and weight the loss\n",
    "            task_loss = loss.mean() * config.weight\n",
    "            task_losses[task_name] = task_loss\n",
    "            total_loss += task_loss\n",
    "        \n",
    "        return total_loss, task_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataGenerator:\n",
    "    \"\"\"Generate synthetic data for multi-task learning\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "        max_history_length: int = 10\n",
    "    ):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_categories = num_categories\n",
    "        self.max_history_length = max_history_length\n",
    "        \n",
    "        # Generate item categories\n",
    "        self.item_categories = torch.randint(\n",
    "            0, num_categories, (num_items,)\n",
    "        )\n",
    "    \n",
    "    def generate_batch(\n",
    "        self,\n",
    "        batch_size: int\n",
    "    ) -> Tuple[KeyedJaggedTensor, KeyedJaggedTensor, MultiTaskTargets]:\n",
    "        # Generate user history\n",
    "        history_lengths = torch.randint(\n",
    "            1, self.max_history_length + 1,\n",
    "            (batch_size,)\n",
    "        )\n",
    "        \n",
    "        history_ids = torch.randint(\n",
    "            0, self.num_items,\n",
    "            (history_lengths.sum(),)\n",
    "        )\n",
    "        \n",
    "        user_features = KeyedJaggedTensor.from_lengths_sync(\n",
    "            keys=[\"history\"],\n",
    "            values=history_ids,\n",
    "            lengths=history_lengths\n",
    "        )\n",
    "        \n",
    "        # Generate candidate items\n",
    "        item_ids = torch.randint(0, self.num_items, (batch_size,))\n",
    "        categories = self.item_categories[item_ids]\n",
    "        \n",
    "        item_features = KeyedJaggedTensor.from_lengths_sync(\n",
    "            keys=[\"item_id\", \"category_id\"],\n",
    "            values=torch.cat([item_ids, categories]),\n",
    "            lengths=torch.ones(batch_size * 2)\n",
    "        )\n",
    "        \n",
    "        # Generate targets\n",
    "        targets = MultiTaskTargets(\n",
    "            click=torch.bernoulli(torch.rand(batch_size) * 0.2),\n",
    "            purchase=torch.bernoulli(torch.rand(batch_size) * 0.05),\n",
    "            watch_time=torch.rand(batch_size) * 3600,  # seconds\n",
    "            rating=torch.randint(1, 6, (batch_size,)).float()\n",
    "        )\n",
    "        \n",
    "        return user_features, item_features, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTrainer:\n",
    "    \"\"\"Training infrastructure for multi-task model\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: MultiTaskRecommender,\n",
    "        loss_fn: MultiTaskLoss,\n",
    "        learning_rate: float = 0.001,\n",
    "        device: str = \"cuda\"\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.device = device\n",
    "        self.debugger = TorchRecDebugger()\n",
    "    \n",
    "    def train_step(\n",
    "        self,\n",
    "        user_features: KeyedJaggedTensor,\n",
    "        item_features: KeyedJaggedTensor,\n",
    "        targets: MultiTaskTargets\n",
    "    ) -> Dict[str, float]:\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Move inputs to device\n",
    "        user_features = user_features.to(self.device)\n",
    "        item_features = item_features.to(self.device)\n",
    "        targets = MultiTaskTargets(*[t.to(self.device) for t in targets])\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = self.model(user_features, item_features)\n",
    "        \n",
    "        # Compute losses\n",
    "        total_loss, task_losses = self.loss_fn.compute_loss(\n",
    "            predictions, targets\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Return losses\n",
    "        return {\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            **{f\"{k}_loss\": v.item() for k, v in task_losses.items()}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskEvaluator:\n",
    "    \"\"\"Evaluate multi-task model performance\"\"\"\n",
    "    def __init__(self, task_configs: Dict[str, TaskConfig]):\n",
    "        self.task_configs = task_configs\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(\n",
    "        self,\n",
    "        predictions: Dict[str, torch.Tensor],\n",
    "        targets: MultiTaskTargets\n",
    "    ) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        \n",
    "        for task_name, pred in predictions.items():\n",
    "            config = self.task_configs[task_name]\n",
    "            target = getattr(targets, task_name)\n",
    "            \n",
    "            if config.metric_type == \"binary\":\n",
    "                # AUC and accuracy for binary tasks\n",
    "                pred_prob = torch.sigmoid(pred.squeeze())\n",
    "                pred_binary = (pred_prob >= 0.5).float()\n",
    "                \n",
    "                metrics[f\"{task_name}_accuracy\"] = (\n",
    "                    (pred_binary == target).float().mean().item()\n",
    "                )\n",
    "                \n",
    "            elif config.metric_type == \"regression\":\n",
    "                # MSE and MAE for regression tasks\n",
    "                pred = pred.squeeze()\n",
    "                metrics[f\"{task_name}_mse\"] = (\n",
    "                    torch.mean((pred - target) ** 2).item()\n",
    "                )\n",
    "                metrics[f\"{task_name}_mae\"] = (\n",
    "                    torch.mean(torch.abs(pred - target)).item()\n",
    "                )\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_task_model():\n",
    "    # Initialize components\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = MultiTaskRecommender(\n",
    "        num_items=10000,\n",
    "        num_categories=100,\n",
    "        embedding_dim=64,\n",
    "        hidden_dim=128\n",
    "    )\n",
    "    \n",
    "    loss_fn = MultiTaskLoss(model.task_configs)\n",
    "    trainer = MultiTaskTrainer(model, loss_fn, device=device)\n",
    "    evaluator = MultiTaskEvaluator(model.task_configs)\n",
    "    \n",
    "    data_gen = MultiTaskDataGenerator(\n",
    "        num_users=10000,\n",
    "        num_items=10000,\n",
    "        num_categories=100\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 5\n",
    "    batch_size = 64\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        \n",
    "        epoch_metrics = {\n",
    "            \"total_loss\": 0.0,\n",
    "            \"click_loss\": 0.0,\n",
    "            \"purchase_loss\": 0.0,\n",
    "            \"watch_time_loss\": 0.0,\n",
    "            \"rating_loss\": 0.0\n",
    "        }\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        for batch in range(100):  # 100 batches per epoch\n",
    "            # Generate batch\n",
    "            user_features, item_features, targets = data_gen.generate_batch(batch_size)\n",
    "            \n",
    "            # Training step\n",
    "            metrics = trainer.train_step(user_features, item_features, targets)\n",
    "            \n",
    "            # Update metrics\n",
    "            for k, v in metrics.items():\n",
    "                epoch_metrics[k] += v\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print(f\"Batch {batch}, Loss: {metrics['total_loss']:.4f}\")\n",
    "        \n",
    "        # Average metrics\n",
    "        for k in epoch_metrics:\n",
    "            epoch_metrics[k] /= 100\n",
    "        \n",
    "        print(\"\\nEpoch Metrics:\")\n",
    "        for k, v in epoch_metrics.items():\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_user_features, eval_item_features, eval_targets = data_gen.generate_batch(1000)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            eval_predictions = model(\n",
    "                eval_user_features.to(device),\n",
    "                eval_item_features.to(device)\n",
    "            )\n",
    "            eval_metrics = evaluator.evaluate(eval_predictions, eval_targets)\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        for k, v in eval_metrics.items():\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
