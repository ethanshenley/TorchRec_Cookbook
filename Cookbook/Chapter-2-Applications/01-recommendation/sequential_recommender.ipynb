{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Recommendation System with TorchRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchrec\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "from utils.data_generators import TorchRecDataGenerator\n",
    "from utils.debugging import TorchRecDebugger\n",
    "from utils.benchmark import TorchRecBenchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SequentialFeatures:\n",
    "    \"\"\"Container for sequential recommendation features\"\"\"\n",
    "    item_ids: torch.Tensor\n",
    "    timestamps: torch.Tensor\n",
    "    categories: torch.Tensor\n",
    "    positions: torch.Tensor  # Position encoding\n",
    "    lengths: torch.Tensor    # Sequence lengths\n",
    "\n",
    "class SequenceEncoder:\n",
    "    \"\"\"Encode sequential data into TorchRec format\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_sequence_length: int,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "    ):\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.num_items = num_items\n",
    "        self.num_categories = num_categories\n",
    "    \n",
    "    def encode_sequence(\n",
    "        self,\n",
    "        features: SequentialFeatures\n",
    "    ) -> KeyedJaggedTensor:\n",
    "        \"\"\"Convert sequence features to KJT format\"\"\"\n",
    "        # Concatenate all features\n",
    "        values = torch.cat([\n",
    "            features.item_ids,\n",
    "            features.categories,\n",
    "            features.positions,\n",
    "            features.timestamps\n",
    "        ])\n",
    "        \n",
    "        # Repeat lengths for each feature type\n",
    "        lengths = features.lengths.repeat(4)  # 4 feature types\n",
    "        \n",
    "        return KeyedJaggedTensor.from_lengths_sync(\n",
    "            keys=[\"item_id\", \"category\", \"position\", \"timestamp\"],\n",
    "            values=values,\n",
    "            lengths=lengths\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRecommender(torch.nn.Module):\n",
    "    \"\"\"Sequential recommendation model with attention\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "        embedding_dim: int = 64,\n",
    "        hidden_dim: int = 128,\n",
    "        num_heads: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding tables\n",
    "        self.embedding_tables = torchrec.EmbeddingBagCollection(\n",
    "            tables=[\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"item_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_items,\n",
    "                    feature_names=[\"item_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"category_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_categories,\n",
    "                    feature_names=[\"category\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"position_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=1000,  # Max sequence length\n",
    "                    feature_names=[\"position\"],\n",
    "                ),\n",
    "            ],\n",
    "            device=torch.device(\"meta\"),\n",
    "        )\n",
    "        \n",
    "        # Time encoding\n",
    "        self.time_encoder = torch.nn.Linear(1, embedding_dim)\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.attention = torch.nn.MultiheadAttention(\n",
    "            embed_dim=embedding_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output layers\n",
    "        self.output_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "    def encode_sequence(\n",
    "        self,\n",
    "        sequence_features: KeyedJaggedTensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode sequence into fixed-length representation\"\"\"\n",
    "        # Get embeddings\n",
    "        embeddings_dict = self.embedding_tables(sequence_features).to_dict()\n",
    "        \n",
    "        # Combine embeddings\n",
    "        item_emb = embeddings_dict[\"item_embeddings\"]\n",
    "        category_emb = embeddings_dict[\"category_embeddings\"]\n",
    "        position_emb = embeddings_dict[\"position_embeddings\"]\n",
    "        \n",
    "        # Encode timestamps\n",
    "        timestamps = sequence_features.values()[\n",
    "            sequence_features.keys().index(\"timestamp\")\n",
    "        ].float().unsqueeze(-1)\n",
    "        time_emb = self.time_encoder(timestamps)\n",
    "        \n",
    "        # Combine all embeddings\n",
    "        sequence_repr = item_emb + category_emb + position_emb + time_emb\n",
    "        \n",
    "        # Apply transformer encoding\n",
    "        sequence_repr = self.transformer_encoder(sequence_repr)\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_out, _ = self.attention(\n",
    "            sequence_repr, sequence_repr, sequence_repr\n",
    "        )\n",
    "        \n",
    "        # Final sequence representation\n",
    "        return self.output_layer(attention_out)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        user_sequence: KeyedJaggedTensor,\n",
    "        candidate_items: KeyedJaggedTensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # Encode user sequence\n",
    "        sequence_repr = self.encode_sequence(user_sequence)\n",
    "        \n",
    "        # Get candidate item embeddings\n",
    "        candidate_embeddings = self.embedding_tables(\n",
    "            candidate_items\n",
    "        ).to_dict()[\"item_embeddings\"]\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        return torch.matmul(sequence_repr, candidate_embeddings.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialDataGenerator:\n",
    "    \"\"\"Generate synthetic sequential data\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "        max_sequence_length: int,\n",
    "        min_sequence_length: int = 2,\n",
    "    ):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_categories = num_categories\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.min_sequence_length = min_sequence_length\n",
    "        \n",
    "        # Generate item categories\n",
    "        self.item_categories = torch.randint(\n",
    "            0, num_categories, (num_items,)\n",
    "        )\n",
    "    \n",
    "    def generate_sequence(\n",
    "        self,\n",
    "        batch_size: int\n",
    "    ) -> Tuple[SequentialFeatures, KeyedJaggedTensor]:\n",
    "        \"\"\"Generate a batch of sequences\"\"\"\n",
    "        # Generate sequence lengths\n",
    "        lengths = torch.randint(\n",
    "            self.min_sequence_length,\n",
    "            self.max_sequence_length + 1,\n",
    "            (batch_size,)\n",
    "        )\n",
    "        \n",
    "        # Generate item IDs\n",
    "        item_ids = torch.randint(\n",
    "            0, self.num_items,\n",
    "            (lengths.sum(),)\n",
    "        )\n",
    "        \n",
    "        # Get categories\n",
    "        categories = self.item_categories[item_ids]\n",
    "        \n",
    "        # Generate timestamps (increasing within sequence)\n",
    "        timestamps = torch.zeros_like(item_ids, dtype=torch.float32)\n",
    "        offset = 0\n",
    "        for i, length in enumerate(lengths):\n",
    "            timestamps[offset:offset + length] = torch.arange(length)\n",
    "            offset += length\n",
    "        \n",
    "        # Generate position encodings\n",
    "        positions = timestamps.clone()\n",
    "        \n",
    "        # Create features\n",
    "        features = SequentialFeatures(\n",
    "            item_ids=item_ids,\n",
    "            timestamps=timestamps,\n",
    "            categories=categories,\n",
    "            positions=positions,\n",
    "            lengths=lengths\n",
    "        )\n",
    "        \n",
    "        # Convert to KJT\n",
    "        encoder = SequenceEncoder(\n",
    "            max_sequence_length=self.max_sequence_length,\n",
    "            num_items=self.num_items,\n",
    "            num_categories=self.num_categories\n",
    "        )\n",
    "        \n",
    "        return features, encoder.encode_sequence(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialTrainer:\n",
    "    \"\"\"Trainer for sequential recommender\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: SequentialRecommender,\n",
    "        learning_rate: float = 0.001,\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.device = device\n",
    "        self.debugger = TorchRecDebugger()\n",
    "    \n",
    "    def train_step(\n",
    "        self,\n",
    "        user_sequence: KeyedJaggedTensor,\n",
    "        target_items: KeyedJaggedTensor,\n",
    "        labels: torch.Tensor,\n",
    "    ) -> float:\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Move to device\n",
    "        user_sequence = user_sequence.to(self.device)\n",
    "        target_items = target_items.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        scores = self.model(user_sequence, target_items)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            scores.view(-1), labels.float()\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sequential_model(\n",
    "    num_users: int = 10000,\n",
    "    num_items: int = 1000,\n",
    "    num_categories: int = 100,\n",
    "    max_sequence_length: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    num_epochs: int = 5,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    # Create model and data generator\n",
    "    model = SequentialRecommender(\n",
    "        num_items=num_items,\n",
    "        num_categories=num_categories\n",
    "    )\n",
    "    \n",
    "    data_gen = SequentialDataGenerator(\n",
    "        num_users=num_users,\n",
    "        num_items=num_items,\n",
    "        num_categories=num_categories,\n",
    "        max_sequence_length=max_sequence_length\n",
    "    )\n",
    "    \n",
    "    trainer = SequentialTrainer(model, device=device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch in range(100):  # 100 batches per epoch\n",
    "            # Generate sequence data\n",
    "            features, sequence_kjt = data_gen.generate_sequence(batch_size)\n",
    "            \n",
    "            # Generate target items (next items in sequence)\n",
    "            target_items = torch.randint(0, num_items, (batch_size,))\n",
    "            target_kjt = KeyedJaggedTensor.from_lengths_sync(\n",
    "                keys=[\"item_id\"],\n",
    "                values=target_items,\n",
    "                lengths=torch.ones(batch_size)\n",
    "            )\n",
    "            \n",
    "            # Generate labels (1 for actual next item, 0 for random items)\n",
    "            labels = torch.zeros(batch_size)\n",
    "            labels[0] = 1  # Assume first item is the true next item\n",
    "            \n",
    "            # Train step\n",
    "            loss = trainer.train_step(sequence_kjt, target_kjt, labels)\n",
    "            epoch_losses.append(loss)\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print(f\"Batch {batch}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} Average Loss: {sum(epoch_losses) / len(epoch_losses):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_sequential_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
