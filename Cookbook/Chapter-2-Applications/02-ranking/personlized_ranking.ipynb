{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Ranking System with TorchRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchrec\n",
    "from typing import Dict, List, Tuple, NamedTuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "from utils.data_generators import TorchRecDataGenerator\n",
    "from utils.debugging import TorchRecDebugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Feature Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserProfile(NamedTuple):\n",
    "    \"\"\"User profile information\"\"\"\n",
    "    historical_items: torch.Tensor    # Previous interactions\n",
    "    historical_cats: torch.Tensor     # Categories of previous interactions\n",
    "    avg_price_level: torch.Tensor     # Average price preference\n",
    "    activity_level: torch.Tensor      # User activity score\n",
    "    category_preferences: torch.Tensor # Category affinity scores\n",
    "    time_of_day: torch.Tensor         # Current time feature\n",
    "\n",
    "class PersonalizedRankingFeatures:\n",
    "    \"\"\"Rich feature set for personalized ranking\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_id: torch.Tensor,\n",
    "        item_id: torch.Tensor,\n",
    "        user_profile: UserProfile,\n",
    "        item_features: Dict[str, torch.Tensor],\n",
    "        interaction_features: Dict[str, torch.Tensor]\n",
    "    ):\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "        self.user_profile = user_profile\n",
    "        self.item_features = item_features\n",
    "        self.interaction_features = interaction_features\n",
    "    \n",
    "    def to(self, device: torch.device) -> 'PersonalizedRankingFeatures':\n",
    "        return PersonalizedRankingFeatures(\n",
    "            user_id=self.user_id.to(device),\n",
    "            item_id=self.item_id.to(device),\n",
    "            user_profile=UserProfile(\n",
    "                *[f.to(device) for f in self.user_profile]\n",
    "            ),\n",
    "            item_features={k: v.to(device) for k, v in self.item_features.items()},\n",
    "            interaction_features={k: v.to(device) for k, v in self.interaction_features.items()}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Interest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInterestModule(torch.nn.Module):\n",
    "    \"\"\"Model user interests from historical behavior\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_heads: int = 4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = torch.nn.MultiheadAttention(\n",
    "            embed_dim=embedding_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.interest_projection = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        history_embeddings: torch.Tensor,\n",
    "        current_context: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # Apply attention using current context as query\n",
    "        attended_history, _ = self.attention(\n",
    "            current_context.unsqueeze(1),\n",
    "            history_embeddings,\n",
    "            history_embeddings\n",
    "        )\n",
    "        \n",
    "        # Project to interest space\n",
    "        user_interests = self.interest_projection(attended_history.squeeze(1))\n",
    "        \n",
    "        return user_interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedRankingModel(torch.nn.Module):\n",
    "    \"\"\"Enhanced ranking model with personalization\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "        embedding_dim: int = 64,\n",
    "        hidden_dim: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding tables\n",
    "        self.embedding_tables = torchrec.EmbeddingBagCollection(\n",
    "            tables=[\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"user_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_users,\n",
    "                    feature_names=[\"user_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"item_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_items,\n",
    "                    feature_names=[\"item_id\"],\n",
    "                ),\n",
    "                torchrec.EmbeddingBagConfig(\n",
    "                    name=\"category_embeddings\",\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_embeddings=num_categories,\n",
    "                    feature_names=[\"category_id\"],\n",
    "                )\n",
    "            ],\n",
    "            device=torch.device(\"meta\")\n",
    "        )\n",
    "        \n",
    "        # User interest modeling\n",
    "        self.user_interest_model = UserInterestModule(\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim\n",
    "        )\n",
    "        \n",
    "        # User profile encoding\n",
    "        self.profile_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, hidden_dim),  # profile features\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        # Item feature encoding\n",
    "        self.item_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim + hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        # Interaction modeling\n",
    "        self.interaction_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim * 3, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        features: PersonalizedRankingFeatures\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # Get base embeddings\n",
    "        embeddings = self.embedding_tables(\n",
    "            KeyedJaggedTensor.from_lengths_sync(\n",
    "                keys=[\"user_id\", \"item_id\"],\n",
    "                values=torch.cat([features.user_id, features.item_id]),\n",
    "                lengths=torch.ones(len(features.user_id) * 2)\n",
    "            )\n",
    "        ).to_dict()\n",
    "        \n",
    "        # Encode user profile\n",
    "        profile_features = torch.stack([\n",
    "            features.user_profile.avg_price_level,\n",
    "            features.user_profile.activity_level,\n",
    "            features.user_profile.category_preferences,\n",
    "            features.user_profile.time_of_day\n",
    "        ], dim=1)\n",
    "        \n",
    "        profile_encoding = self.profile_encoder(profile_features)\n",
    "        \n",
    "        # Get historical item embeddings\n",
    "        history_embeddings = self.embedding_tables(\n",
    "            KeyedJaggedTensor.from_lengths_sync(\n",
    "                keys=[\"item_id\"],\n",
    "                values=features.user_profile.historical_items,\n",
    "                lengths=torch.ones(len(features.user_profile.historical_items))\n",
    "            )\n",
    "        ).to_dict()[\"item_embeddings\"]\n",
    "        \n",
    "        # Model user interests\n",
    "        user_interests = self.user_interest_model(\n",
    "            history_embeddings,\n",
    "            embeddings[\"user_embeddings\"]\n",
    "        )\n",
    "        \n",
    "        # Encode item features\n",
    "        item_features = torch.cat([\n",
    "            embeddings[\"item_embeddings\"],\n",
    "            torch.stack([\n",
    "                features.item_features[\"price\"],\n",
    "                features.item_features[\"age\"],\n",
    "                features.item_features[\"popularity\"]\n",
    "            ], dim=1)\n",
    "        ], dim=1)\n",
    "        \n",
    "        item_encoding = self.item_encoder(item_features)\n",
    "        \n",
    "        # Combine all representations\n",
    "        combined_features = torch.cat([\n",
    "            user_interests,\n",
    "            profile_encoding,\n",
    "            item_encoding\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Generate ranking score\n",
    "        ranking_score = self.interaction_layers(combined_features)\n",
    "        \n",
    "        return {\n",
    "            \"score\": ranking_score,\n",
    "            \"user_encoding\": user_interests,\n",
    "            \"item_encoding\": item_encoding\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Ranking Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedRankingLoss:\n",
    "    \"\"\"Enhanced ranking loss with multiple components\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        margin: float = 0.1,\n",
    "        lambda_reg: float = 0.1\n",
    "    ):\n",
    "        self.margin = margin\n",
    "        self.lambda_reg = lambda_reg\n",
    "    \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        outputs: Dict[str, torch.Tensor],\n",
    "        labels: torch.Tensor,\n",
    "        user_history: torch.Tensor\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        scores = outputs[\"score\"]\n",
    "        user_encoding = outputs[\"user_encoding\"]\n",
    "        item_encoding = outputs[\"item_encoding\"]\n",
    "        \n",
    "        # Basic ranking loss\n",
    "        ranking_loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            scores.squeeze(),\n",
    "            labels.float()\n",
    "        )\n",
    "        \n",
    "        # Contrastive loss for similar items\n",
    "        pos_encoding = item_encoding[labels == 1]\n",
    "        neg_encoding = item_encoding[labels == 0]\n",
    "        \n",
    "        if len(pos_encoding) > 0 and len(neg_encoding) > 0:\n",
    "            contrastive_loss = torch.nn.functional.triplet_margin_loss(\n",
    "                anchor=user_encoding[labels == 1],\n",
    "                positive=pos_encoding,\n",
    "                negative=neg_encoding,\n",
    "                margin=self.margin\n",
    "            )\n",
    "        else:\n",
    "            contrastive_loss = torch.tensor(0.0, device=scores.device)\n",
    "        \n",
    "        # Regularization\n",
    "        reg_loss = self.lambda_reg * (\n",
    "            user_encoding.norm(2) + \n",
    "            item_encoding.norm(2)\n",
    "        )\n",
    "        \n",
    "        total_loss = ranking_loss + contrastive_loss + reg_loss\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"ranking_loss\": ranking_loss,\n",
    "            \"contrastive_loss\": contrastive_loss,\n",
    "            \"reg_loss\": reg_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedDataGenerator:\n",
    "    \"\"\"Generate data for personalized ranking\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        num_categories: int,\n",
    "        max_history_length: int = 20\n",
    "    ):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_categories = num_categories\n",
    "        self.max_history_length = max_history_length\n",
    "        \n",
    "        # Generate item metadata\n",
    "        self.item_categories = torch.randint(0, num_categories, (num_items,))\n",
    "        self.item_prices = torch.rand(num_items) * 100\n",
    "        self.item_ages = torch.rand(num_items) * 365\n",
    "        self.item_popularity = torch.rand(num_items)\n",
    "        \n",
    "        # Generate user profiles\n",
    "        self.user_histories = self._generate_user_histories()\n",
    "        self.user_preferences = self._generate_user_preferences()\n",
    "    \n",
    "    def _generate_user_histories(self) -> Dict[int, List[int]]:\n",
    "        \"\"\"Generate synthetic user interaction histories\"\"\"\n",
    "        histories = {}\n",
    "        for user_id in range(self.num_users):\n",
    "            history_length = np.random.randint(5, self.max_history_length)\n",
    "            histories[user_id] = np.random.choice(\n",
    "                self.num_items,\n",
    "                size=history_length,\n",
    "                replace=False\n",
    "            ).tolist()\n",
    "        return histories\n",
    "    \n",
    "    def _generate_user_preferences(self) -> Dict[int, Dict[str, float]]:\n",
    "        \"\"\"Generate synthetic user preferences\"\"\"\n",
    "        preferences = {}\n",
    "        for user_id in range(self.num_users):\n",
    "            preferences[user_id] = {\n",
    "                \"price_sensitivity\": np.random.beta(2, 5),  # Most users prefer lower prices\n",
    "                \"category_preferences\": torch.rand(self.num_categories),\n",
    "                \"activity_level\": np.random.beta(2, 2)\n",
    "            }\n",
    "        return preferences\n",
    "    \n",
    "    def generate_batch(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        pos_ratio: float = 0.2\n",
    "    ) -> Tuple[PersonalizedRankingFeatures, torch.Tensor]:\n",
    "        # Sample users and items\n",
    "        user_ids = torch.randint(0, self.num_users, (batch_size,))\n",
    "        item_ids = torch.randint(0, self.num_items, (batch_size,))\n",
    "        \n",
    "        # Generate time features\n",
    "        time_of_day = torch.rand(batch_size) * 24  # Hour of day\n",
    "        \n",
    "        # Build user profiles\n",
    "        user_histories = []\n",
    "        user_cats = []\n",
    "        avg_prices = []\n",
    "        activity_levels = []\n",
    "        category_prefs = []\n",
    "        \n",
    "        for user_id in user_ids.numpy():\n",
    "            # Get user history\n",
    "            history = self.user_histories[user_id]\n",
    "            user_histories.extend(history)\n",
    "            user_cats.extend([self.item_categories[item_id] for item_id in history])\n",
    "            \n",
    "            # Get user preferences\n",
    "            prefs = self.user_preferences[user_id]\n",
    "            avg_prices.append(prefs[\"price_sensitivity\"])\n",
    "            activity_levels.append(prefs[\"activity_level\"])\n",
    "            category_prefs.append(prefs[\"category_preferences\"])\n",
    "        \n",
    "        user_profile = UserProfile(\n",
    "            historical_items=torch.tensor(user_histories),\n",
    "            historical_cats=torch.tensor(user_cats),\n",
    "            avg_price_level=torch.tensor(avg_prices),\n",
    "            activity_level=torch.tensor(activity_levels),\n",
    "            category_preferences=torch.stack(category_prefs),\n",
    "            time_of_day=time_of_day\n",
    "        )\n",
    "        \n",
    "        # Get item features\n",
    "        item_features = {\n",
    "            \"price\": self.item_prices[item_ids],\n",
    "            \"age\": self.item_ages[item_ids],\n",
    "            \"popularity\": self.item_popularity[item_ids],\n",
    "            \"category\": self.item_categories[item_ids]\n",
    "        }\n",
    "        \n",
    "        # Generate interaction features\n",
    "        interaction_features = {\n",
    "            \"price_match\": torch.abs(\n",
    "                self.item_prices[item_ids] / 100 - \n",
    "                user_profile.avg_price_level\n",
    "            ),\n",
    "            \"category_match\": torch.tensor([\n",
    "                prefs[cat.item()]\n",
    "                for prefs, cat in zip(category_prefs, item_features[\"category\"])\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "        # Generate labels based on user preferences\n",
    "        label_probs = (\n",
    "            (1 - interaction_features[\"price_match\"]) * 0.4 +\n",
    "            interaction_features[\"category_match\"] * 0.4 +\n",
    "            item_features[\"popularity\"] * 0.2\n",
    "        )\n",
    "        labels = torch.bernoulli(label_probs * pos_ratio)\n",
    "        \n",
    "        features = PersonalizedRankingFeatures(\n",
    "            user_id=user_ids,\n",
    "            item_id=item_ids,\n",
    "            user_profile=user_profile,\n",
    "            item_features=item_features,\n",
    "            interaction_features=interaction_features\n",
    "        )\n",
    "        \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Training Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedRankingTrainer:\n",
    "    \"\"\"Training infrastructure for personalized ranking\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: PersonalizedRankingModel,\n",
    "        loss_fn: PersonalizedRankingLoss,\n",
    "        learning_rate: float = 0.001,\n",
    "        device: str = \"cuda\"\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = device\n",
    "        \n",
    "        # Optimizer with weight decay\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=True\n",
    "        )\n",
    "    \n",
    "    def train_step(\n",
    "        self,\n",
    "        features: PersonalizedRankingFeatures,\n",
    "        labels: torch.Tensor,\n",
    "        user_history: torch.Tensor\n",
    "    ) -> Dict[str, float]:\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Move to device\n",
    "        features = features.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        user_history = user_history.to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self.model(features)\n",
    "        \n",
    "        # Compute losses\n",
    "        losses = self.loss_fn.compute_loss(outputs, labels, user_history)\n",
    "        \n",
    "        # Backward pass\n",
    "        losses[\"total_loss\"].backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return {k: v.item() for k, v in losses.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedRankingEvaluator:\n",
    "    \"\"\"Advanced evaluation metrics for personalized ranking\"\"\"\n",
    "    @staticmethod\n",
    "    def compute_metrics(\n",
    "        outputs: Dict[str, torch.Tensor],\n",
    "        labels: torch.Tensor,\n",
    "        features: PersonalizedRankingFeatures\n",
    "    ) -> Dict[str, float]:\n",
    "        scores = outputs[\"score\"].detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        # Standard ranking metrics\n",
    "        metrics.update(PersonalizedRankingEvaluator._compute_ranking_metrics(\n",
    "            scores, labels\n",
    "        ))\n",
    "        \n",
    "        # Personalization metrics\n",
    "        metrics.update(PersonalizedRankingEvaluator._compute_personalization_metrics(\n",
    "            outputs, features\n",
    "        ))\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_ranking_metrics(\n",
    "        scores: np.ndarray,\n",
    "        labels: np.ndarray\n",
    "    ) -> Dict[str, float]:\n",
    "        # Sort by scores\n",
    "        sorted_indices = np.argsort(-scores.squeeze())\n",
    "        sorted_labels = labels[sorted_indices]\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        # NDCG@k\n",
    "        for k in [5, 10, 20]:\n",
    "            metrics[f\"ndcg@{k}\"] = PersonalizedRankingEvaluator._compute_ndcg(\n",
    "                sorted_labels, k\n",
    "            )\n",
    "        \n",
    "        # MAP@k\n",
    "        for k in [5, 10, 20]:\n",
    "            metrics[f\"map@{k}\"] = PersonalizedRankingEvaluator._compute_map(\n",
    "                sorted_labels, k\n",
    "            )\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_personalization_metrics(\n",
    "        outputs: Dict[str, torch.Tensor],\n",
    "        features: PersonalizedRankingFeatures\n",
    "    ) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        \n",
    "        # Category diversity\n",
    "        recommended_cats = features.item_features[\"category\"][\n",
    "            outputs[\"score\"].squeeze().argsort(descending=True)[:10]\n",
    "        ]\n",
    "        metrics[\"category_diversity\"] = len(set(recommended_cats.tolist())) / 10\n",
    "        \n",
    "        # Price range coverage\n",
    "        recommended_prices = features.item_features[\"price\"][\n",
    "            outputs[\"score\"].squeeze().argsort(descending=True)[:10]\n",
    "        ]\n",
    "        metrics[\"price_range\"] = (\n",
    "            recommended_prices.max() - recommended_prices.min()\n",
    "        ) / 100\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_ndcg(labels: np.ndarray, k: int) -> float:\n",
    "        \"\"\"Compute NDCG@k\"\"\"\n",
    "        if len(labels) < k:\n",
    "            k = len(labels)\n",
    "        \n",
    "        dcg = np.sum(\n",
    "            labels[:k] / np.log2(np.arange(2, k + 2))\n",
    "        )\n",
    "        \n",
    "        ideal_labels = np.sort(labels)[::-1]\n",
    "        idcg = np.sum(\n",
    "            ideal_labels[:k] / np.log2(np.arange(2, k + 2))\n",
    "        )\n",
    "        \n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_map(labels: np.ndarray, k: int) -> float:\n",
    "        \"\"\"Compute MAP@k\"\"\"\n",
    "        if len(labels) < k:\n",
    "            k = len(labels)\n",
    "        \n",
    "        precision_sum = 0\n",
    "        relevant_count = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            if labels[i] == 1:\n",
    "                relevant_count += 1\n",
    "                precision_sum += relevant_count / (i + 1)\n",
    "        \n",
    "        return precision_sum / k if k > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_personalized_ranking_model():\n",
    "    # Initialize components\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = PersonalizedRankingModel(\n",
    "        num_users=10000,\n",
    "        num_items=1000,\n",
    "        num_categories=100\n",
    "    )\n",
    "    \n",
    "    loss_fn = PersonalizedRankingLoss()\n",
    "    trainer = PersonalizedRankingTrainer(model, loss_fn, device=device)\n",
    "    evaluator = PersonalizedRankingEvaluator()\n",
    "    \n",
    "    data_gen = PersonalizedDataGenerator(\n",
    "        num_users=10000,\n",
    "        num_items=1000,\n",
    "        num_categories=100\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    batch_size = 128\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_losses = defaultdict(list)\n",
    "        \n",
    "        for batch in range(100):\n",
    "            features, labels = data_gen.generate_batch(batch_size)\n",
    "            losses = trainer.train_step(\n",
    "                features,\n",
    "                labels,\n",
    "                features.user_profile.historical_items\n",
    "            )\n",
    "            \n",
    "            for k, v in losses.items():\n",
    "                epoch_losses[k].append(v)\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print(f\"Batch {batch}, Loss: {losses['total_loss']:.4f}\")\n",
    "        \n",
    "        # Print epoch metrics\n",
    "        print(\"\\nTraining Metrics:\")\n",
    "        for k, v in epoch_losses.items():\n",
    "            print(f\"{k}: {np.mean(v):.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_metrics = defaultdict(list)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(10):  # 10 eval batches\n",
    "                features, labels = data_gen.generate_batch(256)  # Larger eval batch\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(features)\n",
    "                metrics = evaluator.compute_metrics(outputs, labels, features)\n",
    "                \n",
    "                for k, v in metrics.items():\n",
    "                    eval_metrics[k].append(v)\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        for k, v in eval_metrics.items():\n",
    "            print(f\"{k}: {np.mean(v):.4f}\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        trainer.scheduler.step(np.mean(epoch_losses[\"total_loss\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_personalized_ranking_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
